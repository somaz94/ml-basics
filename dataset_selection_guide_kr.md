# 데이터셋을 선택할 때 고려해야 할 "적합성(Suitability)"과 "기반 개념(Underlying Concept)"

<br/>

## Overview

머신러닝 프로젝트에서 데이터셋을 고르는 일은 단순히 "유명한 데이터"를 고르는 것이 아니다. 좋은 모델은 좋은 데이터로부터 시작되며, 그 데이터는 문제에 '적합'하고 그 구조를 '이해'해야만 제대로 사용할 수 있다.

이번 글에서는 머신러닝 실습이나 연구를 할 때 중요한 두 가지 개념인 적합성(suitability)과 기반 개념(underlying concept)에 대해 이야기해보겠다.

<br/>

## 적합성(Suitability)이란?

적합성이란 간단히 말해, "이 데이터셋이 내 문제를 해결하는 데 적합한가?"를 의미한다.

### 예시
- 분류 문제를 풀고 싶은데, 타깃(Label)이 없는 데이터셋이라면 적합하지 않다.
- 실제 애플리케이션은 시계열 데이터인데, 정적인 샘플만 있다면 부적절하다.

### 적합성 판단 기준
- **레이블의 유무**: 분류/회귀 문제에 필수
- **도메인 일치**: 문제 도메인과 데이터 출처가 일치하는가?
- **데이터 규모**: 너무 작으면 과적합 위험, 너무 크면 처리 부담
- **노이즈와 결측치 비율**: 품질이 떨어지는 데이터는 학습 방해

<br/>

## 기반 개념(Underlying Concept)이란?

데이터셋을 사용할 때 그 배경과 구조, 즉 어떻게 수집되었고 어떤 전제가 있는지를 이해하는 것이 매우 중요하다. 이것이 바로 underlying concept이다.

### 예시
- Adult Income 데이터셋은 1994년 미국 인구 데이터를 기반으로 합니다. → 현대 사회에 바로 적용하면 편향 위험
- Iris 데이터셋은 Fisher의 선형판별분석(LDA)을 위해 만든 고전적인 구조 → 실제 문제보단 실습 목적에 더 적합

### 이해해야 할 underlying 정보들
- **수집 방식**: 설문, 센서, 로그 등
- **데이터의 전처리 여부**: 이미 정제되었는가? 스케일링, 라벨 인코딩 등
- **시간/공간의 맥락**: 언제 어디서 수집되었는가?
- **윤리적 고려**: 개인정보 포함 여부, 편향 가능성 등

<br/>

## 좋은 데이터셋 선택을 위한 요약 체크리스트

| 항목 | 질문 예시 |
|------|-----------|
| 문제 적합성 | 이 데이터는 분류/회귀/클러스터링 중 어떤 문제에 적합한가? |
| 데이터 구조 이해 | 어떤 컬럼이 독립변수/종속변수인가? |
| 배경 정보 파악 | 데이터는 어떤 방식으로 수집되었는가? (설문, 로그 등) |
| 현실성과 일반화 | 실제 환경에 적용 가능한가? 너무 오래된 데이터는 아닌가? |
| 전처리 상태 | 결측치, 이상치, 중복값은 얼마나 있는가? |

<br/>

## 추가 고려사항

### 1. 데이터 품질 지표
- **완전성(Completeness)**: 결측값 비율
- **일관성(Consistency)**: 데이터 형식과 범위의 일관성
- **정확성(Accuracy)**: 실제 값과의 일치도
- **시의성(Timeliness)**: 데이터의 최신성

### 2. 윤리적 고려사항
- **개인정보 보호**: GDPR, CCPA 등 개인정보보호법 준수
- **편향성 검토**: 성별, 인종, 연령 등에 따른 편향 여부
- **투명성**: 데이터 수집 목적과 사용 방법의 명확성

### 3. 기술적 제약사항
- **저장 공간**: 대용량 데이터의 경우 저장 비용 고려
- **처리 시간**: 실시간 처리 요구사항이 있는지 확인
- **라이센스**: 상업적 사용 가능 여부

### 4. 확장성과 유지보수
- **데이터 업데이트**: 정기적인 데이터 갱신 가능성
- **버전 관리**: 데이터셋의 버전 관리 체계
- **문서화**: 데이터 스키마와 메타데이터의 완성도

<br/>

## 실제 프로젝트에서의 적용 사례

### 사례 1: E-commerce 추천 시스템
- **적합성**: 사용자 행동 로그, 상품 정보, 구매 이력
- **기반 개념**: 시계열 특성, 계절성, 사용자 세그먼트
- **고려사항**: 개인정보 보호, 실시간 처리 요구사항

### 사례 2: 의료 진단 시스템
- **적합성**: 의료 영상, 환자 정보, 진단 결과
- **기반 개념**: 의료 표준, 윤리적 가이드라인, 규제 요구사항
- **고려사항**: HIPAA 준수, 전문가 검증, 해석 가능성

### 사례 3: 금융 사기 탐지
- **적합성**: 거래 데이터, 사용자 행동 패턴, 위험 지표
- **기반 개념**: 금융 규제, 실시간 처리, 보안 요구사항
- **고려사항**: 규제 준수, 보안, 오탐 최소화

<br/>

## 데이터셋 평가 프레임워크

### 1단계: 초기 평가
- [ ] 문제 정의와 목표 명확화
- [ ] 데이터셋 후보 목록 작성
- [ ] 기본 메타데이터 수집

### 2단계: 상세 분석
- [ ] 데이터 품질 검사
- [ ] 적합성 평가
- [ ] 기반 개념 이해

### 3단계: 위험 평가
- [ ] 윤리적 고려사항 검토
- [ ] 기술적 제약사항 확인
- [ ] 법적/규제 요구사항 검토

### 4단계: 최종 결정
- [ ] 종합 평가 점수 계산
- [ ] 대안 데이터셋 검토
- [ ] 최종 선택 및 근거 문서화

<br/>

## 마무리

데이터는 단순히 열고 학습시키는 대상이 아닙니다. 문제에 얼마나 적합한지, 그리고 그 배경을 얼마나 잘 이해했는지에 따라 모델의 성능도, 해석 가능성도 달라진다.

실제 프로젝트든, Kaggle이든, 논문 실험이든 간에 "왜 이 데이터를 선택했는가"에 대해 설명할 수 있는 것이 진정한 실력이다.

<br/>

## Reference

- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/)
- [Kaggle Datasets](https://www.kaggle.com/datasets)
- [Google Dataset Search](https://datasetsearch.research.google.com/)
- [AWS Open Data Registry](https://registry.opendata.aws/)
- [Papers with Code](https://paperswithcode.com/datasets)
- [Hugging Face Datasets](https://huggingface.co/datasets)
- [TensorFlow Datasets](https://www.tensorflow.org/datasets)
- [Scikit-learn Datasets](https://scikit-learn.org/stable/datasets.html)

### 추가 읽을거리
- "Data Quality for Machine Learning Tasks" - Google Research
- "Datasheets for Datasets" - Microsoft Research
- "The Dataset Nutrition Label" - MIT Media Lab
- "AI Fairness 360" - IBM Research 