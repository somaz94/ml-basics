"""
ÌïúÍµ≠Ïñ¥ Í∞êÏ†ï Î∂ÑÏÑù Ïú†Ìã∏Î¶¨Ìã∞ Ìï®ÏàòÎì§
"""

import nltk
from typing import Dict, Any, List


def setup_nltk():
    """NLTK ÌïÑÏöî Îç∞Ïù¥ÌÑ∞ Îã§Ïö¥Î°úÎìú"""
    try:
        nltk.data.find('tokenizers/punkt')
    except LookupError:
        nltk.download('punkt')

    try:
        nltk.data.find('corpora/stopwords')
    except LookupError:
        nltk.download('stopwords')

    try:
        nltk.data.find('corpora/wordnet')
    except LookupError:
        nltk.download('wordnet')


def print_model_summary(results: Dict[str, Dict[str, Any]]):
    """Î™®Îç∏ ÏÑ±Îä• ÏöîÏïΩ Ï∂úÎ†•"""
    print("\nüìò Î™®Îç∏ ÎπÑÍµê Î∞è NLP ÌÜµÏ∞∞")
    print("=" * 50)
    print("Î™®Îç∏ ÏÑ±Îä• ÏöîÏïΩ:")
    print("-" * 30)
    for name, result in results.items():
        print(f"{name:15} | Ï†ïÌôïÎèÑ: {result['accuracy']:.3f}")
    print("=" * 50)


def print_nlp_insights():
    """NLP Í¥ÄÎ†® Ìï¥ÏÑù Ï∂úÎ†•"""
    print("\nüìò NLP Ìï¥ÏÑù:")
    print("- TF-IDF: ÌäπÏÑ± Ï∂îÏ∂úÏùÑ ÏúÑÌïú Ïö©Ïñ¥ ÎπàÎèÑ-Ïó≠Î¨∏ÏÑú ÎπàÎèÑ")
    print("- Naive Bayes: Î≤†Ïù¥Ï¶à Ï†ïÎ¶¨Ïóê Í∏∞Î∞òÌïú ÌôïÎ•†Ï†Å Î∂ÑÎ•òÍ∏∞")
    print("- SVM: ÌÖçÏä§Ìä∏ Î∂ÑÎ•òÎ•º ÏúÑÌïú ÏÑúÌè¨Ìä∏ Î≤°ÌÑ∞ Î®∏Ïã†")
    print("- Ïã†Í≤ΩÎßù: Í∞êÏ†ï Î∂ÑÏÑùÏùÑ ÏúÑÌïú Îî•Îü¨Îãù Ï†ëÍ∑ºÎ≤ï")


def print_best_practices():
    """NLP Î™®Î≤î ÏÇ¨Î°Ä Ï∂úÎ†•"""
    print("\nüìò NLP Î™®Î≤î ÏÇ¨Î°Ä:")
    print("- ÌÖçÏä§Ìä∏ Ï†ÑÏ≤òÎ¶¨: ÏÜåÎ¨∏Ïûê Î≥ÄÌôò, ÌäπÏàòÎ¨∏Ïûê Ï†úÍ±∞")
    print("- TF-IDF Î≤°ÌÑ∞Ìôî: Îã®Ïñ¥ Ï§ëÏöîÎèÑ Ìè¨Ï∞©")
    print("- Î∂àÏö©Ïñ¥ Ï†úÍ±∞: ÏùòÎØ∏ ÏûàÎäî Îã®Ïñ¥Ïóê ÏßëÏ§ë")
    print("- N-gram ÌäπÏÑ±: Îã®Ïñ¥ Ï°∞Ìï© Ìè¨Ï∞©")
    print("- ÍµêÏ∞® Í≤ÄÏ¶ù: Î™®Îç∏ ÏùºÎ∞òÌôî Î≥¥Ïû•")


def print_top_features(top_positive_words: List[str], top_negative_words: List[str], top_k: int = 5):
    """ÏÉÅÏúÑ ÌäπÏÑ± Ï∂úÎ†•"""
    print(f"\nüìò Ï£ºÏöî ÌäπÏÑ± (ÏÉÅÏúÑ {top_k}Í∞ú Í∏çÏ†ï Îã®Ïñ¥):")
    for i, word in enumerate(top_positive_words[-top_k:], 1):
        print(f"{i}. {word}")

    print(f"\nüìò Ï£ºÏöî ÌäπÏÑ± (ÏÉÅÏúÑ {top_k}Í∞ú Î∂ÄÏ†ï Îã®Ïñ¥):")
    for i, word in enumerate(top_negative_words[-top_k:], 1):
        print(f"{i}. {word}")


class ModelPredictor:
    """ÌÜµÌï© ÏòàÏ∏° ÌÅ¥ÎûòÏä§"""
    
    def __init__(self, traditional_models, neural_network, tfidf_extractor, text_preprocessor):
        self.traditional_models = traditional_models
        self.neural_network = neural_network
        self.tfidf_extractor = tfidf_extractor
        self.text_preprocessor = text_preprocessor
    
    def predict_sentiment(self, text: str) -> Dict[str, Any]:
        """ÌÖçÏä§Ìä∏Ïùò Í∞êÏ†ïÏùÑ ÏòàÏ∏°"""
        processed_text = self.text_preprocessor.preprocess_text(text)
        tfidf_features = self.tfidf_extractor.transform([processed_text])
        
        predictions = {}
        
        # Ï†ÑÌÜµÏ†Å Î™®Îç∏Îì§
        for name in self.traditional_models.results.keys():
            predictions[name] = self.traditional_models.predict_single(name, tfidf_features)
        
        # Ïã†Í≤ΩÎßù
        if self.neural_network:
            predictions['NeuralNetwork'] = self.neural_network.predict_single(tfidf_features)
        
        # Îã§ÏàòÍ≤∞ Ìà¨Ìëú
        prediction_values = list(predictions.values())
        majority_vote = 1 if sum(prediction_values) > len(prediction_values) / 2 else 0
        sentiment_label = "Í∏çÏ†ï" if majority_vote == 1 else "Î∂ÄÏ†ï"
        
        return {
            'text': text,
            'processed_text': processed_text,
            'predictions': predictions,
            'majority_vote': majority_vote,
            'sentiment': sentiment_label
        }
