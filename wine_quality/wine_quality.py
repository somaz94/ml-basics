import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LinearRegression
from sklearn.cluster import KMeans
from sklearn.metrics import accuracy_score, mean_squared_error

# í•œê¸€ í°íŠ¸ ì„¤ì • (macOS)
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

# ë°ì´í„° ë¡œë“œ (ì™€ì¸ í’ˆì§ˆ ë°ì´í„°)
print("\nì™€ì¸ í’ˆì§ˆ ë°ì´í„° ë¡œë“œ ì¤‘...")
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv"
df = pd.read_csv(url, sep=';')
X = df.drop('quality', axis=1)
y = df['quality']

print(f"ë°ì´í„° shape: {X.shape}, íƒ€ê²Ÿ shape: {y.shape}")

# -----------------------
# ì§€ë„í•™ìŠµ: í’ˆì§ˆ ë“±ê¸‰ ë¶„ë¥˜ (RandomForest)
# -----------------------
print("\nğŸ“˜ ì§€ë„í•™ìŠµ - RandomForestë¡œ ì™€ì¸ í’ˆì§ˆ ë“±ê¸‰ ë¶„ë¥˜")
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
clf = RandomForestClassifier(random_state=42)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
acc = accuracy_score(y_test, y_pred)
print(f"RandomForest ë¶„ë¥˜ ì •í™•ë„: {acc:.3f}")

# -----------------------
# ì§€ë„í•™ìŠµ: í’ˆì§ˆ ì ìˆ˜ íšŒê·€ (LinearRegression)
# -----------------------
print("\nğŸ“˜ ì§€ë„í•™ìŠµ - LinearRegressionìœ¼ë¡œ ì™€ì¸ í’ˆì§ˆ ì ìˆ˜ ì˜ˆì¸¡")
lr = LinearRegression()
lr.fit(X_train, y_train)
y_pred_reg = lr.predict(X_test)
mse = mean_squared_error(y_test, y_pred_reg)
print(f"LinearRegression MSE: {mse:.3f}")

# -----------------------
# ë¹„ì§€ë„í•™ìŠµ: KMeans êµ°ì§‘í™”
# -----------------------
print("\nğŸ“˜ ë¹„ì§€ë„í•™ìŠµ - KMeansë¡œ ì™€ì¸ êµ°ì§‘í™”")
kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(X)
print("KMeans êµ°ì§‘ ê²°ê³¼(0~2):", np.bincount(clusters))
print("ì‹¤ì œ í’ˆì§ˆ ë“±ê¸‰ ë¶„í¬:", np.bincount(y))

# -----------------------
# ì‹œê°í™”: ì•Œì½”ì˜¬-ì‚°ë„-í’ˆì§ˆ ì‚°ì ë„
# -----------------------
plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
plt.scatter(X['alcohol'], X['fixed acidity'], c=y, cmap='viridis', edgecolor='k')
plt.xlabel('ì•Œì½”ì˜¬')
plt.ylabel('ì‚°ë„')
plt.title('ì‹¤ì œ í’ˆì§ˆ ë“±ê¸‰')

plt.subplot(1,2,2)
plt.scatter(X['alcohol'], X['fixed acidity'], c=clusters, cmap='viridis', edgecolor='k')
plt.xlabel('ì•Œì½”ì˜¬')
plt.ylabel('ì‚°ë„')
plt.title('KMeans êµ°ì§‘')
plt.tight_layout()
plt.show() 