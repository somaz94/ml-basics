import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.cluster import KMeans
from sklearn.metrics import accuracy_score, confusion_matrix

# í•œê¸€ í°íŠ¸ ì„¤ì • (macOS)
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

# ë°ì´í„° ë¡œë“œ (seaborn ë‚´ì¥)
print("\níƒ€ì´íƒ€ë‹‰ ë°ì´í„° ë¡œë“œ ì¤‘...")
df = sns.load_dataset('titanic')
print(df.head())

# ì£¼ìš” íŠ¹ì„±ë§Œ ì‚¬ìš© & ê²°ì¸¡ì¹˜/ë²”ì£¼í˜• ì²˜ë¦¬
features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']
df = df[features + ['survived']].dropna()
df['sex'] = df['sex'].map({'male': 0, 'female': 1})
df['embarked'] = df['embarked'].map({'S': 0, 'C': 1, 'Q': 2})

X = df[features]
y = df['survived']

print(f"ë°ì´í„° shape: {X.shape}, íƒ€ê²Ÿ shape: {y.shape}")

# -----------------------
# ì§€ë„í•™ìŠµ: ìƒì¡´ ì˜ˆì¸¡ (DecisionTree, RandomForest, LogisticRegression)
# -----------------------
print("\nğŸ“˜ ì§€ë„í•™ìŠµ - ìƒì¡´ ì˜ˆì¸¡")
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
models = {
    'DecisionTree': DecisionTreeClassifier(),
    'RandomForest': RandomForestClassifier(random_state=42),
    'LogisticRegression': LogisticRegression(max_iter=200)
}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    print(f"{name} ì •í™•ë„: {acc:.3f}")

# -----------------------
# ë¹„ì§€ë„í•™ìŠµ: KMeans êµ°ì§‘í™”
# -----------------------
print("\nğŸ“˜ ë¹„ì§€ë„í•™ìŠµ - KMeansë¡œ ìŠ¹ê° ê·¸ë£¹ ë¶„ì„")
kmeans = KMeans(n_clusters=2, random_state=42)
clusters = kmeans.fit_predict(X)
print("KMeans êµ°ì§‘ ê²°ê³¼(0/1):", np.bincount(clusters))
print("ì‹¤ì œ ìƒì¡´ì ë¶„í¬:", np.bincount(y))
print("êµ°ì§‘-ì‹¤ì œ ìƒì¡´ì í˜¼ë™ í–‰ë ¬:\n", confusion_matrix(y, clusters))

# -----------------------
# ì‹œê°í™”: ë‚˜ì´-ìš”ê¸ˆ-ìƒì¡´ ì‚°ì ë„
# -----------------------
plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
plt.scatter(X['age'], X['fare'], c=y, cmap='coolwarm', edgecolor='k')
plt.xlabel('ë‚˜ì´')
plt.ylabel('ìš”ê¸ˆ')
plt.title('ì‹¤ì œ ìƒì¡´ ì—¬ë¶€')

plt.subplot(1,2,2)
plt.scatter(X['age'], X['fare'], c=clusters, cmap='coolwarm', edgecolor='k')
plt.xlabel('ë‚˜ì´')
plt.ylabel('ìš”ê¸ˆ')
plt.title('KMeans êµ°ì§‘')
plt.tight_layout()
plt.show() 